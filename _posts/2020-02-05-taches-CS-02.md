---
layout: post
title:  "Trouver la bonne méthode pour mesurer la réussite des tâches en ligne"
pubdate: "February 5, 2020"
langpage: "https://blog.canada.ca/2020/02/05/CS-02-tasks.html"
date:   2020-02-05
published: true
draft: true
lang: fr
alt: "CS-02 tasks"
description: "Ce que nous avons appris des rapports de réussite des tâches CS-02 en ligne"
---

En 2019, le Bureau de la transformation numérique a travaillé avec ses collègues de la Division des résultats du Secrétariat du Conseil du Trésor pour mettre en place un nouvel indicateur de rendement clé. Celui-ci évalue la capacité des citoyens d’accomplir des tâches aux exigences élevées sur le site Web du gouvernement du Canada. Trente-sept ministères ont dû faire rapport sur le nouvel indicateur en 2019.

La mesure de l’achèvement des tâches en ligne nous aide à comprendre comment les améliorations apportées à la conception influent sur la réussite des tâches. Elle aide également les institutions à adopter une approche axée sur les tâches principales pour la gestion de l’information et des services en ligne.

En analysant les résultats au début de 2020, nous avons beaucoup appris sur les différentes méthodes de mesure de la réussite des tâches en ligne.

## Contexte

Le nom officiel du nouvel indicateur est « Services de communication - Résultat 2 (SC-O2) ». Cet indicateur fait partie des indicateurs des services internes en vertu de la  [Politique sur les Résultats](https://www.tbs-sct.gc.ca/pol/doc-fra.aspx?id=31300).  

L’établissement de rapports sur cet indicateur pousse les institutions du gouvernement du Canada à faire de la prestation de services une priorité. Cela les aide à planifier leur travail numérique en vue d’améliorer leur réussite pour les tâches principales en ligne. Cette démarche s’harmonise avec les [Normes numériques du gouvernement du Canada](https://www.canada.ca/fr/gouvernement/systeme/gouvernement-numerique/normes-numeriques-gouvernement-canada.html) sur l’habilitation du personnel à offrir de meilleurs services.

<blockquote><p style="color: #1E5D71 !important;">« Changez les paramètres clés et vous changerez l’organisation. Changez l’organisation et vous livrerez des services numériques grandement supérieurs. »»

</p>
</blockquote>

<p>-[Gerry McGovern, February 2018](https://blog.canada.ca/2018/02/23/Improve-digital-services-measuring-outcomes.html)</p>

Dans un esprit d’expérimentation et de respect des ressources disponibles, le Bureau de la transformation numérique a proposé trois méthodes pour réaliser ce rapport :

* l’essai de convivialité;
* l’analyse d’entonnoirs de tâches;
* l’enquête sur l’achèvement des tâches.

## Mode de mesure des tâches dans l’ensemble des établissements déclarants

Nous avons compilé les données que chaque établissement a envoyées. Nous avons associé à chaque tâche la méthode de collecte, le nombre de participants, la période et le taux de réussite. Voici ce que nous avons constaté :

<b>Méthode de déclaration</b>

* 9 sondages
* 8 essais de convivialité
* 7 analyses d’entonnoirs de tâches
* 2 autres méthodes

<b>Types de tâches déclarées</b>
* 283 tâches déclarées
* Plus de 200 tâches liées à la recherche de réponses à des questions
* 23 tâches étaient liées à la présentation d’une demande, au renouvellement, au classement ou à l’enregistrement
* 15 tâches étaient liées à la façon de nous contacter
* 15 tâches étaient liées à la recherche d’emplois et de carrières
* 18 tâches étaient liées au téléchargement, à l’ouverture de session, à l’achat ou au calcul

#### Réussite d’achèvement de la tâche

Nous avons considéré le taux de réussite pour toutes les tâches qui étaient testées avec plus de 20 participants. 101 tâches répondaient à ce critère.
* Le taux de réussite moyen de ces 101 tâches était de 64 %.
* 32 tâches ont obtenu une cote de réussite élevée de plus de 80 %

Neuf établissements ont connu un franc succès en ce qui concerne une tâche. Il s’agissait surtout de tâches liées à la recherche de réponses. Les sujets abordés comprenaient les temps d’attente à la frontière, les possibilités de carrière et les conseils de santé aux voyageurs.

Lower performing tasks often included applying or registering for things. It’s difficult to pinpoint the cause of the lower success rates. Possible causes include:

* le type de méthode de déclaration (les entonnoirs de tâches étaient souvent utilisés)
* la nature de la tâche étant plus complexe avec les exigences en ligne et hors ligne combinées
* des problèmes liés à l’expérience réelle en ligne.

## Les avantages et les inconvénients de chaque méthode de déclaration

Voici ce que nous avons appris au sujet de chaque méthode de production de rapport.

### Essais de convivialité

L’essai de convivialité dirigé est une formidable façon de découvrir comment les visiteurs utilisent votre site et de cerner où se trouvent les problèmes. C’est aussi la norme d’excellence pour mesurer la réussite d’une tâche. Toutefois, les essais de convivialité axés sur l’achèvement des tâches sont un peu différents des essais de convivialité standards. La principale différence est que les essais relatifs à l’achèvement des tâches ont tendance à faire appel à un plus grand nombre de participants (au moins 16). Cet essai est axé à la fois sur l’obtention d’une cote de réussite fiable par tâche et sur la découverte du mode d’utilisation du site par les visiteurs.

Les résultats des essais de convivialité dirigés sont difficiles à comparer entre de nombreux établissements. La comparabilité dépend de l’uniformité de la formulation des tâches et des scénarios. De plus, il peut être difficile pour les petits établissements d’assurer le coût, le temps et l’expertise nécessaires pour effectuer et analyser des essais de convivialité rigoureux.

Cela dit, rien ne peut remplacer l’observation de personnes en chair et en os qui utilisent votre site. Nous recommandons toujours d’intégrer les essais de convivialité à la trousse d’outils de votre équipe Web.

### Entonnoirs de tâches

Cette option a permis aux établissements de faire rapport sur une seule tâche. Ils ont utilisé les outils analytiques Web anonymisés pour suivre les parcours des visiteurs depuis le début d’une tâche jusqu’à l’achèvement réussi.

Les entonnoirs fonctionnent mieux pour suivre les conversions sur plusieurs pages où il y a une seule séquence d’étapes à suivre (comme une caisse de commerce électronique). L’inconvénient est que les visiteurs abandonnent les entonnoirs pour des raisons qui n’ont rien à voir avec l’efficacité de l’expérience.

Cette méthode n’est pas idéale pour les tâches liées à la recherche de réponses. Celles-ci aboutissent souvent à des options multiples, de sort qu’il est difficile ou impossible de suivre le cheminement de l’utilisateur.

Bon nombre des établissements qui ont utilisé cette méthode ont également signalé que la désuétude des plateformes d’analyse et l’incapacité de suivre les utilisateurs dans les zones sécurisées d’un site Web compliquaient l’analyse.   

Nous avons constaté que la qualité des données que nous avons reçues des entonnoirs de tâches était mitigée. Cette méthode était parfois confondue avec une étude sur la répérabilité. On a demandé aux utilisateurs s’ils pouvaient trouver des liens à partir d’une page définie. Il existe de meilleures méthodes pour déterminer la répérabilité, comme [l’essai de l’arborescence ou l’essai des clics](https://www.nngroup.com/articles/navigation-ia-tests/).

### Sondage en ligne

Le sondage en ligne était la méthode privilégiée pour recueillir des données sur la réussite des tâches principales. Nous avons constaté qu’il donnait des résultats comparables d’un établissement à l’autre. Pour les établissements qui entreprennent leur parcours à partir de la gestion des tâches principales, la méthode du sondage est la plus facile à mettre en œuvre et à reproduire année après année.

Le Bureau de la transformation numérique a élaboré un sondage que n’importe quel établissement pourrait utiliser. Les établissements n’avaient qu’à rédiger leurs scénarios de tâches et à accorder suffisamment de temps pour exécuter le sondage. Ce sondage était la seule méthode qui permettait les réponses par écrit. Cette méthode a permis aux établissements de découvrir des tâches nouvelles ou sous-représentées.   

Les résultats des sondages ont été compilés automatiquement dans des tableaux de bord. Cela a réduit davantage la charge de travail de l’établissement pour la compilation et l’analyse des données.

Le sondage du Bureau de la transformation numérique demandait aux visiteurs de:

* choisir la tâche qu’ils sont venus faire (y compris une option d’édition au cas où leur tâche ne serait pas indiquée);
* confirmer s’ils ont été en mesure d’accomplir leur tâche
* choisir la raison pour laquelle ils n’ont pas été en mesure d’accomplir leur tâche (y compris une option d’édition) s’ils n’ont pas pu le faire;

We found that this method allowed the best balance between:

* standardizing data
* helping institutions understand why people visit their pages
* pinpointing the parts of the online experience causing service delivery issues

The first round of reports uncovered challenges in terms of ease of execution and data quality.  We’re taking these findings into consideration as we plan the 2020 exercise.

## Simplifying our methods for better results

Offering multiple methods to report on top tasks was meant to remove barriers to data collection. The reality was that it affected our ability to see trends across institutions. The different methods created inconsistent data. It’s hard to compare the results of a task funnel to a usability test!  

## Moving forward: A single reporting method for 2020

It’s clear that a single reporting method would help us see the big picture of online task delivery across the Government of Canada.

The online survey method provides a standardized data collection method. It is technically easy to implement, and provides clear data about top task strengths and weaknesses.

The feedback we heard from institutions using this method was positive. It indicated a culture shift to top task management.

* “The survey allows us to prioritize which section on the website should be optimized first, for example our focus/energy should go towards top tasks that are not performing as [well] as the other ones.” - Global Affairs Canada

* “Over the course of time, the findings of WES (Web Experience Survey) have played a part in the evolution of the Statistics Canada website.” - Statistics Canada

For the next task collection request in 2020, we will ask that institutions use an online survey.

## Final word

In 2020, all institutions subject to the [Policy on Communications and Federal Identity](https://www.tbs-sct.gc.ca/pol/doc-eng.aspx?id=30683) (Schedules I, I.1 and II of the [Financial Administration Act](https://laws-lois.justice.gc.ca/eng/acts/F-11/page-30.html#docCont)) will be asked to report.


### We want to hear from you

What would make online top task reporting easier for you to complete?

* tips and best practices for writing top task survey questions
* advice on how to break down big tasks into smaller, measurable steps
* instructions on what to do if your service includes online and offline delivery channels
* other suggestions?

## Inspired by what you learned? Share this post with your team.

 Connect with the Digital Transformation Office at TBS:
* Email: [dto-btn@tbs-sct.gc.ca](mailto:dto-btn@tbs-sct.gc.ca)
* Twitter: #Canadadotca
* Slack: [http://design-GC-conception.slack.com](https://design-gc-conception.slack.com/join/shared_invite/enQtODE1OTc5Mzg5NzQ4LWQ3MjZjMTdjMjk2ZTZmMTJjYWQ3ZmRiNDYwYjRmN2NjYzQyNjFlNDBlY2FkNWE1ODg2YjExY2QwZmVjN2MwMGM)

## Learn more

* [Improve digital services by measuring outcomes](https://blog.canada.ca/2018/02/23/Improve-digital-services-measuring-outcomes.html)
* [See how we identify top tasks for Canada.ca](https://blog.canada.ca/2017/12/11/top-100-for-gc.html)
* [See how measuring task success is key for optimizing Canada.ca top tasks](https://blog.canada.ca/2017/12/12/optimization-overview.html)
