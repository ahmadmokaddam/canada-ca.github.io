---
layout: post
title:  "Trouver la bonne méthode pour mesurer la réussite des tâches en ligne"
pubdate: "February 5, 2020"
langpage: "https://blog.canada.ca/2020/02/05/CS-02-tasks.html"
date:   2020-02-05
published: true
draft: true
lang: fr
alt: "CS-02 tasks"
description: "Ce que nous avons appris des rapports de réussite des tâches CS-02 en ligne"
---

En 2019, le Bureau de la transformation numérique a travaillé avec ses collègues de la Division des résultats du Secrétariat du Conseil du Trésor pour mettre en place un nouvel indicateur de rendement clé. Celui-ci évalue la capacité des citoyens d’accomplir des tâches aux exigences élevées sur le site Web du gouvernement du Canada. Trente-sept ministères ont dû faire rapport sur le nouvel indicateur en 2019.

La mesure de l’achèvement des tâches en ligne nous aide à comprendre comment les améliorations apportées à la conception influent sur la réussite des tâches. Elle aide également les institutions à adopter une approche axée sur les tâches principales pour la gestion de l’information et des services en ligne.

En analysant les résultats au début de 2020, nous avons beaucoup appris sur les différentes méthodes de mesure de la réussite des tâches en ligne.

## Contexte

Le nom officiel du nouvel indicateur est « Services de communication - Résultat 2 (SC-O2) ». Cet indicateur fait partie des indicateurs des services internes en vertu de la  [Politique sur les Résultats](https://www.tbs-sct.gc.ca/pol/doc-fra.aspx?id=31300).  

L’établissement de rapports sur cet indicateur pousse les institutions du gouvernement du Canada à faire de la prestation de services une priorité. Cela les aide à planifier leur travail numérique en vue d’améliorer leur réussite pour les tâches principales en ligne. Cette démarche s’harmonise avec les [Normes numériques du gouvernement du Canada](https://www.canada.ca/fr/gouvernement/systeme/gouvernement-numerique/normes-numeriques-gouvernement-canada.html) sur l’habilitation du personnel à offrir de meilleurs services.

<blockquote><p style="color: #1E5D71 !important;">« Changez les paramètres clés et vous changerez l’organisation. Changez l’organisation et vous livrerez des services numériques grandement supérieurs. »»

</p>
</blockquote>

<p>-[Gerry McGovern, February 2018](https://blog.canada.ca/2018/02/23/Improve-digital-services-measuring-outcomes.html)</p>

Dans un esprit d’expérimentation et de respect des ressources disponibles, le Bureau de la transformation numérique a proposé trois méthodes pour réaliser ce rapport :

* l’essai de convivialité;
* l’analyse d’entonnoirs de tâches;
* l’enquête sur l’achèvement des tâches.

## Mode de mesure des tâches dans l’ensemble des établissements déclarants

Nous avons compilé les données que chaque établissement a envoyées. Nous avons associé à chaque tâche la méthode de collecte, le nombre de participants, la période et le taux de réussite. Voici ce que nous avons constaté :

<b>Méthode de déclaration</b>

* 9 sondages
* 8 essais de convivialité
* 7 analyses d’entonnoirs de tâches
* 2 autres méthodes

<b>Types de tâches déclarées</b>
* 283 tâches déclarées
* Plus de 200 tâches liées à la recherche de réponses à des questions
* 23 tâches étaient liées à la présentation d’une demande, au renouvellement, au classement ou à l’enregistrement
* 15 tâches étaient liées à la façon de nous contacter
* 15 tâches étaient liées à la recherche d’emplois et de carrières
* 18 tâches étaient liées au téléchargement, à l’ouverture de session, à l’achat ou au calcul

#### Réussite d’achèvement de la tâche

Nous avons considéré le taux de réussite pour toutes les tâches qui étaient testées avec plus de 20 participants. 101 tâches répondaient à ce critère.
* Le taux de réussite moyen de ces 101 tâches était de 64 %.
* 32 tâches ont obtenu une cote de réussite élevée de plus de 80 %

Neuf établissements ont connu un franc succès en ce qui concerne une tâche. Il s’agissait surtout de tâches liées à la recherche de réponses. Les sujets abordés comprenaient les temps d’attente à la frontière, les possibilités de carrière et les conseils de santé aux voyageurs.

Lower performing tasks often included applying or registering for things. It’s difficult to pinpoint the cause of the lower success rates. Possible causes include:

* le type de méthode de déclaration (les entonnoirs de tâches étaient souvent utilisés)
* la nature de la tâche étant plus complexe avec les exigences en ligne et hors ligne combinées
* des problèmes liés à l’expérience réelle en ligne.

## Les avantages et les inconvénients de chaque méthode de déclaration

Voici ce que nous avons appris au sujet de chaque méthode de production de rapport.

### Essais de convivialité

L’essai de convivialité dirigé est une formidable façon de découvrir comment les visiteurs utilisent votre site et de cerner où se trouvent les problèmes. C’est aussi la norme d’excellence pour mesurer la réussite d’une tâche. Toutefois, les essais de convivialité axés sur l’achèvement des tâches sont un peu différents des essais de convivialité standards. La principale différence est que les essais relatifs à l’achèvement des tâches ont tendance à faire appel à un plus grand nombre de participants (au moins 16). Cet essai est axé à la fois sur l’obtention d’une cote de réussite fiable par tâche et sur la découverte du mode d’utilisation du site par les visiteurs.

Les résultats des essais de convivialité dirigés sont difficiles à comparer entre de nombreux établissements. La comparabilité dépend de l’uniformité de la formulation des tâches et des scénarios. De plus, il peut être difficile pour les petits établissements d’assurer le coût, le temps et l’expertise nécessaires pour effectuer et analyser des essais de convivialité rigoureux.

Cela dit, rien ne peut remplacer l’observation de personnes en chair et en os qui utilisent votre site. Nous recommandons toujours d’intégrer les essais de convivialité à la trousse d’outils de votre équipe Web.

### Entonnoirs de tâches

Cette option a permis aux établissements de faire rapport sur une seule tâche. Ils ont utilisé les outils analytiques Web anonymisés pour suivre les parcours des visiteurs depuis le début d’une tâche jusqu’à l’achèvement réussi.

Les entonnoirs fonctionnent mieux pour suivre les conversions sur plusieurs pages où il y a une seule séquence d’étapes à suivre (comme une caisse de commerce électronique). L’inconvénient est que les visiteurs abandonnent les entonnoirs pour des raisons qui n’ont rien à voir avec l’efficacité de l’expérience.

This method is not great for answer-finding tasks. These often have multiple path options making them difficult or impossible to track.

Several of those who used this method also noted that they found it challenging because of outdated analytics platforms and the inability to track users through secure areas of a website.  

We found that the quality of data we received from task funnels was mixed. This method was sometimes confused with a findability study. Users were asked if they were able to find links from a defined page. There are better methods to determine findability such as [tree testing or click testing](https://www.nngroup.com/articles/navigation-ia-tests/).

### Online survey

An online survey was the preferred method for collecting top task success data. We found it delivered comparable results across institutions. For institutions beginning their journey in top task management, the survey method is the easiest to implement and rerun year after year.

The Digital Transformation Office developed a survey that any institution could use. Institutions only needed to write their task scenarios and allow sufficient time to run the survey. This survey was the only method that allowed write-in responses. That gave institutions the chance to uncover new or under-represented tasks.  

Results from the surveys were automatically collected into dashboards. This further reduced the institution’s workload for compiling and analyzing the data.

The Digital Transformation Office survey prompted visitors to:

* select the task that they came to do (including a write-in option in case their task wasn’t listed)
* confirm if they were able to complete their task
* select why they were not able to complete their task (including a write-in option) if they couldn’t

We found that this method allowed the best balance between:

* standardizing data
* helping institutions understand why people visit their pages
* pinpointing the parts of the online experience causing service delivery issues

The first round of reports uncovered challenges in terms of ease of execution and data quality.  We’re taking these findings into consideration as we plan the 2020 exercise.

## Simplifying our methods for better results

Offering multiple methods to report on top tasks was meant to remove barriers to data collection. The reality was that it affected our ability to see trends across institutions. The different methods created inconsistent data. It’s hard to compare the results of a task funnel to a usability test!  

## Moving forward: A single reporting method for 2020

It’s clear that a single reporting method would help us see the big picture of online task delivery across the Government of Canada.

The online survey method provides a standardized data collection method. It is technically easy to implement, and provides clear data about top task strengths and weaknesses.

The feedback we heard from institutions using this method was positive. It indicated a culture shift to top task management.

* “The survey allows us to prioritize which section on the website should be optimized first, for example our focus/energy should go towards top tasks that are not performing as [well] as the other ones.” - Global Affairs Canada

* “Over the course of time, the findings of WES (Web Experience Survey) have played a part in the evolution of the Statistics Canada website.” - Statistics Canada

For the next task collection request in 2020, we will ask that institutions use an online survey.

## Final word

In 2020, all institutions subject to the [Policy on Communications and Federal Identity](https://www.tbs-sct.gc.ca/pol/doc-eng.aspx?id=30683) (Schedules I, I.1 and II of the [Financial Administration Act](https://laws-lois.justice.gc.ca/eng/acts/F-11/page-30.html#docCont)) will be asked to report.


### We want to hear from you

What would make online top task reporting easier for you to complete?

* tips and best practices for writing top task survey questions
* advice on how to break down big tasks into smaller, measurable steps
* instructions on what to do if your service includes online and offline delivery channels
* other suggestions?

## Inspired by what you learned? Share this post with your team.

 Connect with the Digital Transformation Office at TBS:
* Email: [dto-btn@tbs-sct.gc.ca](mailto:dto-btn@tbs-sct.gc.ca)
* Twitter: #Canadadotca
* Slack: [http://design-GC-conception.slack.com](https://design-gc-conception.slack.com/join/shared_invite/enQtODE1OTc5Mzg5NzQ4LWQ3MjZjMTdjMjk2ZTZmMTJjYWQ3ZmRiNDYwYjRmN2NjYzQyNjFlNDBlY2FkNWE1ODg2YjExY2QwZmVjN2MwMGM)

## Learn more

* [Improve digital services by measuring outcomes](https://blog.canada.ca/2018/02/23/Improve-digital-services-measuring-outcomes.html)
* [See how we identify top tasks for Canada.ca](https://blog.canada.ca/2017/12/11/top-100-for-gc.html)
* [See how measuring task success is key for optimizing Canada.ca top tasks](https://blog.canada.ca/2017/12/12/optimization-overview.html)
