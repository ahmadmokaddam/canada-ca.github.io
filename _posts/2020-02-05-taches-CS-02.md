---
layout: post
title:  "Trouver la bonne méthode pour mesurer la réussite des tâches en ligne"
pubdate: "February 5, 2020"
langpage: "https://blog.canada.ca/2020/02/05/CS-02-tasks.html"
date:   2020-02-05
published: true
draft: true
lang: fr
alt: "CS-02 tasks"
description: "Ce que nous avons appris des rapports de réussite des tâches CS-02 en ligne"
---

En 2019, le Bureau de la transformation numérique a travaillé avec ses collègues de la Division des résultats du Secrétariat du Conseil du Trésor pour mettre en place un nouvel indicateur de rendement clé. Celui-ci évalue la capacité des citoyens d’accomplir des tâches aux exigences élevées sur le site Web du gouvernement du Canada. Trente-sept ministères ont dû faire rapport sur le nouvel indicateur en 2019.

La mesure de l’achèvement des tâches en ligne nous aide à comprendre comment les améliorations apportées à la conception influent sur la réussite des tâches. Elle aide également les institutions à adopter une approche axée sur les tâches principales pour la gestion de l’information et des services en ligne.

En analysant les résultats au début de 2020, nous avons beaucoup appris sur les différentes méthodes de mesure de la réussite des tâches en ligne.

## Contexte

Le nom officiel du nouvel indicateur est « Services de communication - Résultat 2 (SC-O2) ». Cet indicateur fait partie des indicateurs des services internes en vertu de la  [Politique sur les Résultats](https://www.tbs-sct.gc.ca/pol/doc-fra.aspx?id=31300).  

L’établissement de rapports sur cet indicateur pousse les institutions du gouvernement du Canada à faire de la prestation de services une priorité. Cela les aide à planifier leur travail numérique en vue d’améliorer leur réussite pour les tâches principales en ligne. Cette démarche s’harmonise avec les [Normes numériques du gouvernement du Canada](https://www.canada.ca/fr/gouvernement/systeme/gouvernement-numerique/normes-numeriques-gouvernement-canada.html) sur l’habilitation du personnel à offrir de meilleurs services.

<blockquote><p style="color: #1E5D71 !important;">« Change the key metrics and you will change the organization. Change the organization and you will deliver vastly better digital services. »»

</p>
</blockquote>

<p>-[Gerry McGovern, February 2018](https://blog.canada.ca/2018/02/23/Improve-digital-services-measuring-outcomes.html)</p>

In the spirit of experimentation and respect for available resources, the Digital Transformation Office offered 3 methods to complete this report:

* usability testing
* task funnel analysis
* task completion survey

## How tasks were measured across the reporting institutions

We compiled the data that each institution sent. We tagged each task with the collection method, number of participants, time period, and success rate.  Here’s what we found.

<b>Reporting method</b>
* 9 Surveys
* 8 Usability tests
* 7 Task funnels
* 2 Other methods

<b>Types of tasks reported </b>
* 283 reported tasks
* Over 200 tasks about looking for answers to questions
* 23 tasks about applying, renewing, filing, or registering
* 15 contact us tasks
* 15 jobs and careers seeking tasks
* 18 tasks about downloading, signing in, purchasing, or calculating

#### Task success

We looked at the success rate for all tasks that were tested with over 20 participants. 101 tasks met this criteria.
* The average success rate for these 101 tasks was 64%
* 32 tasks had a high success rating of over 80%

9 institutions had high success tasks. These were mostly answer-finding tasks. Topics included border wait times, career opportunities, and travel health notices.

Lower performing tasks often included applying or registering for things. It’s difficult to pinpoint the cause of the lower success rates. Possible causes include:

* the type of reporting method (task funnels were often used)
* the nature of the task being more complex with both online and offline requirements
* issues with the actual online experience

## The pros and cons of each reporting method

Here’s what we learned about each reporting method.

### Usability testing

Moderated usability testing is a fantastic way to learn about how people use your site, and to see where there are problems. It’s also the gold standard for measuring task success. But, usability tests focused on task performance are a bit different from standard usability testing. The main difference is that task performance testing tends to use more participants (at least 16). It focuses both on arriving at a reliable success score per task and on learning about how people use the site.

Moderated usability testing results are difficult to compare across many institutions. They rely on phrasing tasks and scenarios consistently. As well, the cost, time and expertise needed to run and analyze rigorous usability tests can be challenging for smaller institutions.

That said, nothing can replace watching real people use your site. We always recommend incorporating usability testing into your web team’s toolkit.

### Task funnel

This option gave institutions the ability to report on a single task. They used anonymized web analytics to track visitors’ paths from beginning a task, to the successful completion.

Funnels work best for tracking conversions over multiple pages where there is a single sequence of steps to follow (such as an e-commerce checkout). The drawback is that people drop out of funnels for reasons that have nothing to do with the effectiveness of the experience.

This method is not great for answer-finding tasks. These often have multiple path options making them difficult or impossible to track.

Several of those who used this method also noted that they found it challenging because of outdated analytics platforms and the inability to track users through secure areas of a website.  

We found that the quality of data we received from task funnels was mixed. This method was sometimes confused with a findability study. Users were asked if they were able to find links from a defined page. There are better methods to determine findability such as [tree testing or click testing](https://www.nngroup.com/articles/navigation-ia-tests/).

### Online survey

An online survey was the preferred method for collecting top task success data. We found it delivered comparable results across institutions. For institutions beginning their journey in top task management, the survey method is the easiest to implement and rerun year after year.

The Digital Transformation Office developed a survey that any institution could use. Institutions only needed to write their task scenarios and allow sufficient time to run the survey. This survey was the only method that allowed write-in responses. That gave institutions the chance to uncover new or under-represented tasks.  

Results from the surveys were automatically collected into dashboards. This further reduced the institution’s workload for compiling and analyzing the data.

The Digital Transformation Office survey prompted visitors to:

* select the task that they came to do (including a write-in option in case their task wasn’t listed)
* confirm if they were able to complete their task
* select why they were not able to complete their task (including a write-in option) if they couldn’t

We found that this method allowed the best balance between:

* standardizing data
* helping institutions understand why people visit their pages
* pinpointing the parts of the online experience causing service delivery issues

The first round of reports uncovered challenges in terms of ease of execution and data quality.  We’re taking these findings into consideration as we plan the 2020 exercise.

## Simplifying our methods for better results

Offering multiple methods to report on top tasks was meant to remove barriers to data collection. The reality was that it affected our ability to see trends across institutions. The different methods created inconsistent data. It’s hard to compare the results of a task funnel to a usability test!  

## Moving forward: A single reporting method for 2020

It’s clear that a single reporting method would help us see the big picture of online task delivery across the Government of Canada.

The online survey method provides a standardized data collection method. It is technically easy to implement, and provides clear data about top task strengths and weaknesses.

The feedback we heard from institutions using this method was positive. It indicated a culture shift to top task management.

* “The survey allows us to prioritize which section on the website should be optimized first, for example our focus/energy should go towards top tasks that are not performing as [well] as the other ones.” - Global Affairs Canada

* “Over the course of time, the findings of WES (Web Experience Survey) have played a part in the evolution of the Statistics Canada website.” - Statistics Canada

For the next task collection request in 2020, we will ask that institutions use an online survey.

## Final word

In 2020, all institutions subject to the [Policy on Communications and Federal Identity](https://www.tbs-sct.gc.ca/pol/doc-eng.aspx?id=30683) (Schedules I, I.1 and II of the [Financial Administration Act](https://laws-lois.justice.gc.ca/eng/acts/F-11/page-30.html#docCont)) will be asked to report.


### We want to hear from you

What would make online top task reporting easier for you to complete?

* tips and best practices for writing top task survey questions
* advice on how to break down big tasks into smaller, measurable steps
* instructions on what to do if your service includes online and offline delivery channels
* other suggestions?

## Inspired by what you learned? Share this post with your team.

 Connect with the Digital Transformation Office at TBS:
* Email: [dto-btn@tbs-sct.gc.ca](mailto:dto-btn@tbs-sct.gc.ca)
* Twitter: #Canadadotca
* Slack: [http://design-GC-conception.slack.com](https://design-gc-conception.slack.com/join/shared_invite/enQtODE1OTc5Mzg5NzQ4LWQ3MjZjMTdjMjk2ZTZmMTJjYWQ3ZmRiNDYwYjRmN2NjYzQyNjFlNDBlY2FkNWE1ODg2YjExY2QwZmVjN2MwMGM)

## Learn more

* [Improve digital services by measuring outcomes](https://blog.canada.ca/2018/02/23/Improve-digital-services-measuring-outcomes.html)
* [See how we identify top tasks for Canada.ca](https://blog.canada.ca/2017/12/11/top-100-for-gc.html)
* [See how measuring task success is key for optimizing Canada.ca top tasks](https://blog.canada.ca/2017/12/12/optimization-overview.html)
